{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4db6de69",
   "metadata": {},
   "source": [
    "# Week 4 Lab: Model Preparation & Evaluation\n",
    "\n",
    "Welcome to this week's lab on **Model Preparation and Evaluation**. We'll be covering the following key concepts:\n",
    "- Train/Validation/Test Splits\n",
    "- Avoiding Data Leakage\n",
    "- Using Pipelines for cleaner workflows\n",
    "- Model Evaluation Metrics (like MSE and R²)\n",
    "- Hyperparameter Tuning with GridSearchCV\n",
    "\n",
    "---\n",
    "## Part 1: Train/Test/Validation Split\n",
    "We'll use the California Housing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8283d614",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "data = fetch_california_housing(as_frame=True)\n",
    "df = data.frame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a9f82e",
   "metadata": {},
   "source": [
    "Let's split the data into features and target.\n",
    "- Features are the columns we use to predict\n",
    "- The target is what we want to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b308b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns='MedHouseVal')\n",
    "y = df['MedHouseVal']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d5ba02",
   "metadata": {},
   "source": [
    "Now let's split into train and test sets using `train_test_split` from sklearn.\n",
    "We’ll use 60% training, 20% validation, 20% test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf065f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42)  # 0.25 x 0.8 = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c01726f",
   "metadata": {},
   "source": [
    "## Part 2: Pipelines\n",
    "Let’s build a simple pipeline to standardize the features and apply Linear Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb2cfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "print(\"Model trained!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d29ab0",
   "metadata": {},
   "source": [
    "## Part 3: Evaluation\n",
    "Now we’ll check how well our model performs using R² and MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3276b358",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "y_pred = pipeline.predict(X_val)\n",
    "print(\"MSE:\", mean_squared_error(y_val, y_pred))\n",
    "print(\"R²:\", r2_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a62707f",
   "metadata": {},
   "source": [
    "## Part 4: Optional - Try GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e03190",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('ridge', Ridge())\n",
    "])\n",
    "\n",
    "params = {'ridge__alpha': [0.1, 1.0, 10.0]}\n",
    "grid = GridSearchCV(pipeline, param_grid=params, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best alpha:\", grid.best_params_)\n",
    "print(\"Best score (R²):\", grid.best_score_)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
